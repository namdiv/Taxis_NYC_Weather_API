{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 03: Data cleaning and transformation\n",
    "\n",
    "In this file we clean the data for a better future analysis. We divide this stage in steps:\n",
    "\n",
    "1. Importing libraries\n",
    "2. Loading the data\n",
    "3. Data cleaning and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: data cleaning and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Deleting innecesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['congestion_surcharge','airport_fee'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Deleting duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Column renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns =\n",
    "                    {'VendorID':'id_vendor',\n",
    "                    'RatecodeID':'id_ratecode',\n",
    "                    'PULocationID':'id_pu_zone',\n",
    "                    'DOLocationID':'id_do_zone'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) We created a new column, fare_per_mile, to study the relation between fare_amount and trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_distance_aux'] = df['trip_distance']\n",
    "df['trip_distance_aux'].replace(0, 1, inplace=True)\n",
    "df['trip_distance_aux'].fillna(1, inplace=True)\n",
    "\n",
    "df['fare_per_mile'] = df.fare_amount / df.trip_distance_aux\n",
    "\n",
    "df.loc[df['trip_distance'] == 0, 'fare_per_mile'] = 0\n",
    "\n",
    "df.drop(columns=['trip_distance_aux'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) We created a new column, trip_time, to identify the trip time in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate the time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_time'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we converted it to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.trip_time = df.trip_time.dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) We created a new column, fare_per_minute, for indetify the relation between fare_amount and el trip_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_time_aux'] = df['trip_time']\n",
    "df['trip_time_aux'].replace(0, 1, inplace=True)\n",
    "df['trip_time_aux'].fillna(1, inplace=True)\n",
    "\n",
    "df['fare_per_minute'] = df.fare_amount / (df.trip_time_aux / 60)\n",
    "\n",
    "df.loc[df['trip_time'] == 0, 'fare_per_minute'] = 0\n",
    "\n",
    "df.drop(columns=['trip_time_aux'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Starting to work with zones dataset and boroughs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the taxi zones dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = pd.read_csv('https://raw.githubusercontent.com/soyHenry/DS-Proyecto_Grupal_TaxisNYC/main/taxi%2B_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone.rename(columns =\n",
    "                    {'LocationID':'id_zone',\n",
    "                    'Borough':'borough',\n",
    "                    'Zone':'zone'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the boroughs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_data = {'id_borough': [1, 2, 3, 4, 5, 6, 7], 'borough':['Brooklyn', 'Bronx', 'Manhattan', 'Staten Island', 'Queens', 'EWR', 'Unknown']}\n",
    "df_borough = pd.DataFrame(borough_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a zones dictionary with their respective borough so then we can map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_zone_borough = {df_zone.id_zone[i] : df_zone.borough[i] for i in range (0,len(df_zone))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a borough dictionary with their respective id so then we can map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_id_borough = {df_borough.borough[i] : df_borough.id_borough[i] for i in range (0, len(df_borough))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two new columns: pu_borough: \"pull up borough\" and do_borough: \"drop off borough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pu_borough'] = df.id_pu_zone.map(dic_zone_borough)\n",
    "df['do_borough'] = df.id_do_zone.map(dic_zone_borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an id_borough in the taxis dataframe so then we can do the relationship in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_borough'] = df.pu_borough.map(dic_id_borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h) We create a new column, id_time_borough, for then do the relationship in SQL with the weather table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_time_borough'] = df.tpep_pickup_datetime.dt.strftime('%Y%m%d%H') + df.id_borough.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Indetifying outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating outliers column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['outlier'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating interqualtile range, min, max\n",
    "IQR = df.trip_distance.quantile(.75) - df.trip_distance.quantile(.25)\n",
    "min = df.trip_distance.quantile(.25) - (1.5 * IQR)\n",
    "max = df.trip_distance.quantile(.75) + (1.5 * IQR)\n",
    "\n",
    "# Identifying outliers\n",
    "df.loc[df.trip_distance < min, \"outlier\"] = 0\n",
    "df.loc[df.trip_distance > max, \"outlier\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating interqualtile range, min, max\n",
    "IQR = df.fare_amount.quantile(.75) - df.fare_amount.quantile(.25)\n",
    "min = df.fare_amount.quantile(.25) - (1.5 * IQR)\n",
    "max = df.fare_amount.quantile(.75) + (1.5 * IQR)\n",
    "\n",
    "# Identifying outliers\n",
    "df.loc[df.fare_amount < min, \"outlier\"] = 0\n",
    "df.loc[df.fare_amount > max, \"outlier\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers trip_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating interqualtile range, min, max\n",
    "IQR = df.trip_time.quantile(.75) - df.trip_time.quantile(.25)\n",
    "min = df.trip_time.quantile(.25) - (1.5 * IQR)\n",
    "max = df.trip_time.quantile(.75) + (1.5 * IQR)\n",
    "\n",
    "# Identifying outliers\n",
    "df.loc[df.trip_time < min, \"outlier\"] = 0\n",
    "df.loc[df.trip_time > max, \"outlier\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_trip'] = df.index.values\n",
    "df['id_trip'] = df['id_trip'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "df = df[cols[25:26] + cols[0:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime_snow'] = df.tpep_pickup_datetime.dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('taxi.csv', index=False)\n",
    "df_zone.to_csv('zone.csv', index=False)\n",
    "df_borough.to_csv('borough.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce8db2a0a97b6d15ccbb150412aa5502326b7928cb570dbce8e0f4a9461b766e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
